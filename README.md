# üöÄ Treinamento Modern Data Stack

## üîç Sobre este Projeto
Este treinamento completo sobre Modern Data Stack foi desenvolvido para profissionais que desejam dominar as principais ferramentas e pr√°ticas do ecossistema moderno de dados. Com foco em casos pr√°ticos de an√°lise de voos e hospedagens, o treinamento oferece uma experi√™ncia hands-on com as tecnologias mais relevantes do mercado.

## üìã √çndice

- [Objetivos](#-objetivos)
- [P√∫blico-Alvo](#-p√∫blico-alvo)
- [Pr√©-requisitos](#-pr√©-requisitos)
- [Tecnologias Abordadas](#%EF%B8%8F-tecnologias-abordadas)
- [Cronograma](#-cronograma)
- [Estrutura do Treinamento](#%EF%B8%8F-estrutura-do-treinamento)
- [M√≥dulos](#-m√≥dulos)
- [Setup do Ambiente](#%EF%B8%8F-setup-do-ambiente)
- [Avalia√ß√£o](#-avalia√ß√£o)
- [Recursos Adicionais](#-recursos-adicionais)
- [Suporte](#-suporte)

## üéØ Objetivos
- Dominar os fundamentos da Modern Data Stack
- Desenvolver pipelines de dados completos
- Implementar boas pr√°ticas de engenharia de dados
- Criar solu√ß√µes escal√°veis e manuten√≠veis

## üîç P√∫blico-Alvo
- Engenheiros de Dados
- Analistas de Dados
- Cientistas de Dados
- Desenvolvedores interessados em dados

## üìö Pr√©-requisitos
- Conhecimento b√°sico de Python
- Familiaridade com SQL
- No√ß√µes de linha de comando
- Conceitos b√°sicos de Cloud Computing

## ‚öôÔ∏è Tecnologias Abordadas
- Docker e Docker Compose
- Apache Airflow
- Apache Spark
- Google BigQuery
- DBT (Data Build Tool)
- DuckDB (banco de dados anal√≠tico local)
- Metabase

## üìÖ Cronograma

```
+------------------------------------------------------------------------------+
|                           Cronograma do Treinamento                           |
+---------------+---------------------------+--------------------------------+
| M√≥dulo        | Data In√≠cio              | Dura√ß√£o                        |
+---------------+---------------------------+--------------------------------+
| Fundamentos   | 2024-01-01               | ‚ñà‚ñà‚ñà 3 dias                     |
| Docker        | 2024-01-04               | ‚ñà‚ñà‚ñà 3 dias                     |
| Airflow       | 2024-01-07               | ‚ñà‚ñà‚ñà 3 dias                     |
| DBT           | 2024-01-10               | ‚ñà‚ñà‚ñà 3 dias                     |
| Spark         | 2024-01-13               | ‚ñà‚ñà‚ñà 3 dias                     |
| BigQuery      | 2024-01-16               | ‚ñà‚ñà‚ñà 3 dias                     |
| Projeto Final | 2024-01-19               | ‚ñà‚ñà‚ñà 3 dias                     |
+---------------+---------------------------+--------------------------------+
```

## üó∫Ô∏è Estrutura do Treinamento

```
                    +-------------------+
                    | Modern Data Stack |
                    +-------------------+
                             |
         +------------------+------------------+
         |        |        |        |         |         |         |
         v        v        v        v         v         v         v
+----------------+  +----------+  +---------+  +-----+  +-------+  +---------+  +-------------+
| 1. Fundamentos |  | 2.Docker |  |3.Airflow|  |4.DBT|  |5.Spark|  |6.BigQuery|  |7.Proj.Final |
+----------------+  +----------+  +---------+  +-----+  +-------+  +---------+  +-------------+
```

## üìÇ M√≥dulos

### [M√≥dulo 1: Fundamentos da Modern Data Stack](modulos/01-fundamentos)
- Introdu√ß√£o √† Modern Data Stack
- Arquitetura de Dados Moderna
- Conceitos Fundamentais
- Setup do Ambiente

### [M√≥dulo 2: Docker para Ambientes de Dados](modulos/02-docker)
- Fundamentos do Docker
- Containeriza√ß√£o de Aplica√ß√µes
- Docker Compose
- Boas Pr√°ticas

### [M√≥dulo 3: Apache Airflow - Orquestra√ß√£o de Dados](modulos/03-airflow)
- Fundamentos do Airflow
- Desenvolvimento de DAGs
- Operadores e Sensores
- Monitoramento

### [M√≥dulo 4: DBT - Transforma√ß√£o de Dados](modulos/04-dbt)
- Fundamentos do DBT
- Modelagem de Dados
- Testes e Documenta√ß√£o
- Boas Pr√°ticas

### [M√≥dulo 5: Apache Spark - Processamento Distribu√≠do](modulos/05-spark)
- Fundamentos do Spark
- PySpark
- Otimiza√ß√£o
- Integra√ß√£o

### [M√≥dulo 6: BigQuery e Data Warehouse](modulos/06-bigquery)
- Fundamentos de DW
- BigQuery
- Otimiza√ß√£o
- Custos

### [M√≥dulo 7: Projeto Final Integrado](modulos/07-projeto-final)
- Sistema Completo
- Integra√ß√£o
- Documenta√ß√£o
- Apresenta√ß√£o

## üõ†Ô∏è Setup do Ambiente

### Requisitos de Sistema
- Docker 24.0+
- Python 3.8+
- Git
- 8GB RAM (m√≠nimo)
- 50GB espa√ßo em disco

### Instala√ß√£o
1. Clone o reposit√≥rio
```bash
git clone https://github.com/seu-usuario/modern-data-stack-training.git
cd modern-data-stack-training
```

2. Configure o ambiente
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
.\venv\Scripts\activate   # Windows
pip install -r requirements.txt
```

3. Inicie os servi√ßos
```bash
docker-compose up -d
```

4. Verifique a instala√ß√£o
```bash
python verify_environment.py
```

## üìä Avalia√ß√£o
- Exerc√≠cios Pr√°ticos: 30%
- Quizzes: 20%
- Projeto Final: 50%

## üìö Recursos Adicionais
- [Modern Data Stack Blog](https://www.moderndatastack.xyz/blog)
- [Data Engineering Roadmap](https://roadmap.sh/data-engineer)
- [DBT Best Practices](https://docs.getdbt.com/best-practices)
- [Airflow Documentation](https://airflow.apache.org/docs/)

## üë®‚Äçüè´ Suporte
- Discord: [Link para servidor]
- GitHub Issues: [Link para issues]
- Email: suporte@moderndatastack.com

## ü¶Ü DuckDB: SQL Anal√≠tico Local e Prototipagem

O DuckDB √© um banco de dados anal√≠tico embutido, orientado a colunas, projetado para processamento anal√≠tico local (OLAP) de alta performance. Ele √© ideal para:
- Laborat√≥rios de SQL
- Prototipagem de pipelines
- Testes r√°pidos sem necessidade de infraestrutura

### Instala√ß√£o
O DuckDB j√° est√° inclu√≠do no `requirements.txt`. Para instalar manualmente:
```bash
pip install duckdb
```

### Exemplo r√°pido de uso em Python
```python
import duckdb

# Cria um banco em mem√≥ria e executa uma query
con = duckdb.connect()
con.execute("CREATE TABLE voos (id INTEGER, origem VARCHAR, destino VARCHAR)")
con.execute("INSERT INTO voos VALUES (1, 'GRU', 'JFK'), (2, 'JFK', 'LHR')")
result = con.execute("SELECT * FROM voos").fetchdf()
print(result)
```

### Documenta√ß√£o
- [Documenta√ß√£o oficial do DuckDB](https://duckdb.org/docs/)
- [dbt-duckdb adapter](https://docs.getdbt.com/reference/warehouse-setups/duckdb-setup) 